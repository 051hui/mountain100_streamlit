# pages/ì±—ë´‡ì¶”ì²œ.py
import pandas as pd
import streamlit as st
import os
import sys

# ìƒìœ„ ë””ë ‰í† ë¦¬ì˜ utilsë¥¼ importí•˜ê¸° ìœ„í•´
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from utils.router import route_intent
from utils.llm_client import GeminiClient
from utils.translator import translate_plan
from utils.recommender import run_recommender
from utils.llm_prompts import (
    EXPLAIN_SYSTEM_PROMPT, 
    make_explain_user_prompt,
    QA_SYSTEM_PROMPT,
    make_qa_user_prompt
)


# -----------------------------------------------------------------------------
# ë°ì´í„° ë¡œë“œ
# -----------------------------------------------------------------------------
@st.cache_data
def load_trails() -> pd.DataFrame:
    """ë“±ì‚°ë¡œ ë°ì´í„° ë¡œë“œ"""
    try:
        current_dir = os.path.dirname(os.path.abspath(__file__))
        root_dir = os.path.dirname(current_dir)
        file_path = os.path.join(root_dir, 'data', '100mountains_dashboard.csv')
        
        df = pd.read_csv(file_path)
        
        full_columns = [
            'ì½”ìŠ¤ëª…', 'ì‚°ì´ë¦„', 'ìœ í˜•ì„¤ëª…', 'ìµœê³ ê³ ë„_m', 'ëˆ„ì ìƒìŠ¹_m', 'í¸ë„ê±°ë¦¬_km', 'ì´ê±°ë¦¬_km', 
            'ì˜ˆìƒì‹œê°„_ë¶„', 'ì˜ˆìƒì‹œê°„', 'ì¶œë°œ_lat', 'ì¶œë°œ_lon', 'ë„ì°©_lat', 'ë„ì°©_lon', 
            'ë‚œì´ë„', 'ì„¸ë¶€ë‚œì´ë„', 'ë‚œì´ë„ì ìˆ˜', 'ê´€ê´‘ì¸í”„ë¼ì ìˆ˜', 'ì£¼ì°¨ì¥_ì ‘ê·¼ì„±ì ìˆ˜', 
            'ì •ë¥˜ì¥_ì ‘ê·¼ì„±ì ìˆ˜', 'ì½”ìŠ¤ìˆ˜', 'ê°€ì¤‘ì¹˜', 'ë§¤ë ¥ì¢…í•©ì ìˆ˜',
            'ì „ë§', 'íë§', 'ì‚¬ì§„', 'ë“±ì‚°ë¡œ', 'ì„±ì·¨ê°', 'ê³„ì ˆë§¤ë ¥', 'íŠ¹ì¶œë§¤ë ¥', 'íŠ¹ì¶œì ìˆ˜',
            'ì£¼ì°¨ì¥ê±°ë¦¬_m', 'ì •ë¥˜ì¥ê±°ë¦¬_m', 'ìœ„ì¹˜', 'ì£¼ì°¨ì¥ëª…', 'ì •ë¥˜ì¥ëª…', 'Cluster'
        ]
        
        if len(df.columns) == len(full_columns):
            df.columns = full_columns
        
        numeric_cols = [
            'ë‚œì´ë„ì ìˆ˜', 'ê´€ê´‘ì¸í”„ë¼ì ìˆ˜', 'ë§¤ë ¥ì¢…í•©ì ìˆ˜', 
            'ì£¼ì°¨ì¥ê±°ë¦¬_m', 'ì •ë¥˜ì¥ê±°ë¦¬_m', 'ì´ê±°ë¦¬_km', 'ìµœê³ ê³ ë„_m', 'Cluster'
        ]
        
        for col in numeric_cols:
            if col in df.columns:
                if col == 'ì£¼ì°¨ì¥ê±°ë¦¬_m':
                    df[col] = pd.to_numeric(df[col], errors='coerce').fillna(-1)
                else:
                    df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
        
        str_cols = ['ì£¼ì°¨ì¥ëª…', 'ì •ë¥˜ì¥ëª…', 'ìœ„ì¹˜']
        for col in str_cols:
            if col in df.columns:
                df[col] = df[col].fillna("-")
        
        return df
        
    except FileNotFoundError:
        st.error(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        return pd.DataFrame()


# -----------------------------------------------------------------------------
# LLM ê¸°ë°˜ ìì—°ìŠ¤ëŸ¬ìš´ ì‘ë‹µ ìƒì„±
# -----------------------------------------------------------------------------
def generate_conversational_recommendation(client: GeminiClient, user_input: str, plan: dict, results: pd.DataFrame) -> str:
    """LLMì„ ì‚¬ìš©í•˜ì—¬ ìì—°ìŠ¤ëŸ¬ìš´ ì¶”ì²œ ì‘ë‹µ ìƒì„±"""
    
    if results.empty:
        return "ì£„ì†¡í•´ìš”, ë§ì”€í•˜ì‹  ì¡°ê±´ì— ë§ëŠ” ë“±ì‚°ë¡œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ğŸ˜…\n\nì¡°ê±´ì„ ì¡°ê¸ˆ ì™„í™”í•´ì„œ ë‹¤ì‹œ ë§ì”€í•´ì£¼ì‹œê² ì–´ìš”?"
    
    # ì¶”ì²œ ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ë¡œ ì •ë¦¬
    trails_info = []
    for idx, row in results.head(3).iterrows():  # ìƒìœ„ 3ê°œë§Œ
        trail_text = f"""
{row['ì‚°ì´ë¦„']} {row['ì½”ìŠ¤ëª…']} ({row['ìœ„ì¹˜']})
- ë‚œì´ë„: {row['ì„¸ë¶€ë‚œì´ë„']}
- ì´ ê±°ë¦¬: {row['ì´ê±°ë¦¬_km']:.1f}km
- ê³ ë„: {row['ìµœê³ ê³ ë„_m']:.0f}m
- ì˜ˆìƒ ì‹œê°„: {row['ì˜ˆìƒì‹œê°„']}
- ì¸í”„ë¼ ì ìˆ˜: {row['ê´€ê´‘ì¸í”„ë¼ì ìˆ˜']:.1f}/10
- ë§¤ë ¥ë„: {row['ë§¤ë ¥ì¢…í•©ì ìˆ˜']:.1f}ì 
- íŠ¹ì¶œ ë§¤ë ¥: {row['íŠ¹ì¶œë§¤ë ¥']} ({row['íŠ¹ì¶œì ìˆ˜']:.1f}ì )
"""
        trails_info.append(trail_text.strip())
    
    trails_text = "\n\n".join(trails_info)
    
    # LLM í”„ë¡¬í”„íŠ¸
    system_prompt = """ë‹¹ì‹ ì€ ì¹œê·¼í•œ ë“±ì‚°ë¡œ ì¶”ì²œ ì±—ë´‡ 'ë“±ì‚¬ë‹ˆ'ì…ë‹ˆë‹¤.

ì—­í• :
- ì‚¬ìš©ìì˜ ìš”ì²­ì„ ë¶„ì„í•œ ê²°ê³¼ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì„¤ëª…í•©ë‹ˆë‹¤
- ì¶”ì²œ ë“±ì‚°ë¡œë¥¼ ëŒ€í™”í•˜ë“¯ì´ ì†Œê°œí•©ë‹ˆë‹¤
- ê° ë“±ì‚°ë¡œì˜ íŠ¹ì§•ì„ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•©ë‹ˆë‹¤
- ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•˜ì—¬ ì¹œê·¼ê°ì„ ì¤ë‹ˆë‹¤

ì‘ë‹µ í˜•ì‹:
1. ì‚¬ìš©ì ì¡°ê±´ì„ ì •ë¦¬í•˜ì—¬ í™•ì¸
2. ì¶”ì²œ ë“±ì‚°ë¡œë¥¼ ìˆœì„œëŒ€ë¡œ ì†Œê°œ (ê° ë“±ì‚°ë¡œë§ˆë‹¤ ì¶”ì²œ ì´ìœ ì™€ íŠ¹ì§• ì„¤ëª…)
3. ê°€ì¥ ì¶”ì²œí•˜ëŠ” ì½”ìŠ¤ë¥¼ ê°•ì¡°í•˜ë©° ë§ˆë¬´ë¦¬
4. ì¶”ê°€ ì§ˆë¬¸ ìœ ë„

ì£¼ì˜ì‚¬í•­:
- ë°ì´í„°ì— ì—†ëŠ” ì •ë³´ëŠ” ë§Œë“¤ì§€ ë§ˆì„¸ìš”
- ìì—°ìŠ¤ëŸ½ê³  ì¹œê·¼í•œ ë§íˆ¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”
- ê° ë“±ì‚°ë¡œë‹¹ 3-4ë¬¸ì¥ ì •ë„ë¡œ ì„¤ëª…í•˜ì„¸ìš”"""

    user_prompt = f"""ì‚¬ìš©ì ìš”ì²­: "{user_input}"

ì¶”ì²œëœ ë“±ì‚°ë¡œ ì •ë³´:
{trails_text}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ë“±ì‚°ë¡œë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì¶”ì²œí•´ì£¼ì„¸ìš”."""

    try:
        response = client.complete_text(system_prompt, user_prompt)
        return response
    except Exception as e:
        # Fallback
        fallback = f"""ì¢‹ìŠµë‹ˆë‹¤! ì‚¬ìš©ìë‹˜ì˜ ì¡°ê±´ì„ ì •ë¦¬í•˜ë©´:
{plan.get('notes_for_ui', 'ë§ì¶¤ ë“±ì‚°ë¡œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤')}

ğŸ”ï¸ ì‚¬ìš©ìë‹˜ì˜ ì„±í–¥ì— ë§ëŠ” ë“±ì‚¬ë‹ˆ ì¶”ì²œ ë“±ì‚°ë¡œ

"""
        for idx, row in results.head(3).iterrows():
            fallback += f"""**{row['ì‚°ì´ë¦„']} {row['ì½”ìŠ¤ëª…']}** ({row['ìœ„ì¹˜']})
ì¶”ì²œ ì´ìœ : ë‚œì´ë„ {row['ì„¸ë¶€ë‚œì´ë„']}, {row['íŠ¹ì¶œë§¤ë ¥']} ì ìˆ˜ê°€ ë†’ìŠµë‹ˆë‹¤.
íŠ¹ì§•: ì´ {row['ì´ê±°ë¦¬_km']:.1f}km, ì˜ˆìƒ ì‹œê°„ {row['ì˜ˆìƒì‹œê°„']}

"""
        
        fallback += "\nì–´ë– ì„¸ìš”? ë” ê¶ê¸ˆí•œ ì ì´ë‚˜ ë‹¤ë¥¸ ì˜µì…˜ì´ í•„ìš”í•˜ì‹œë©´ ë§ì”€í•´ì£¼ì„¸ìš”! ğŸŒ²"
        return fallback


def generate_trail_detail_explanation(client: GeminiClient, trail_name: str, trail_data: pd.Series) -> str:
    """íŠ¹ì • ë“±ì‚°ë¡œì— ëŒ€í•œ ìƒì„¸ ì„¤ëª… ìƒì„±"""
    
    trail_info = f"""
ë“±ì‚°ë¡œ: {trail_data['ì‚°ì´ë¦„']} {trail_data['ì½”ìŠ¤ëª…']}
ìœ„ì¹˜: {trail_data['ìœ„ì¹˜']}
ìœ í˜•: {trail_data['ìœ í˜•ì„¤ëª…']}
ë‚œì´ë„: {trail_data['ì„¸ë¶€ë‚œì´ë„']} (ì ìˆ˜: {trail_data['ë‚œì´ë„ì ìˆ˜']})
ì´ ê±°ë¦¬: {trail_data['ì´ê±°ë¦¬_km']:.1f}km (í¸ë„: {trail_data['í¸ë„ê±°ë¦¬_km']:.1f}km)
ìµœê³  ê³ ë„: {trail_data['ìµœê³ ê³ ë„_m']:.0f}m
ëˆ„ì  ìƒìŠ¹: {trail_data['ëˆ„ì ìƒìŠ¹_m']:.0f}m
ì˜ˆìƒ ì‹œê°„: {trail_data['ì˜ˆìƒì‹œê°„']}
ì¶œë°œ ì§€ì : ìœ„ë„ {trail_data['ì¶œë°œ_lat']}, ê²½ë„ {trail_data['ì¶œë°œ_lon']}
ë„ì°© ì§€ì : ìœ„ë„ {trail_data['ë„ì°©_lat']}, ê²½ë„ {trail_data['ë„ì°©_lon']}
ì£¼ì°¨ì¥: {trail_data['ì£¼ì°¨ì¥ëª…']} (ê±°ë¦¬: {trail_data['ì£¼ì°¨ì¥ê±°ë¦¬_m']:.0f}m)
ì •ë¥˜ì¥: {trail_data['ì •ë¥˜ì¥ëª…']} (ê±°ë¦¬: {trail_data['ì •ë¥˜ì¥ê±°ë¦¬_m']:.0f}m)
ê´€ê´‘ ì¸í”„ë¼ ì ìˆ˜: {trail_data['ê´€ê´‘ì¸í”„ë¼ì ìˆ˜']:.1f}/10
ë§¤ë ¥ ì¢…í•© ì ìˆ˜: {trail_data['ë§¤ë ¥ì¢…í•©ì ìˆ˜']:.1f}ì 
ë§¤ë ¥ ìš”ì†Œ:
- ì „ë§: {trail_data['ì „ë§']:.1f}
- íë§: {trail_data['íë§']:.1f}
- ì‚¬ì§„: {trail_data['ì‚¬ì§„']:.1f}
- ë“±ì‚°ë¡œ: {trail_data['ë“±ì‚°ë¡œ']:.1f}
- ì„±ì·¨ê°: {trail_data['ì„±ì·¨ê°']:.1f}
- ê³„ì ˆë§¤ë ¥: {trail_data['ê³„ì ˆë§¤ë ¥']:.1f}
íŠ¹ì¶œ ë§¤ë ¥: {trail_data['íŠ¹ì¶œë§¤ë ¥']} ({trail_data['íŠ¹ì¶œì ìˆ˜']:.1f}ì )
"""
    
    system_prompt = """ë‹¹ì‹ ì€ ì¹œê·¼í•œ ë“±ì‚°ë¡œ ì•ˆë‚´ ì±—ë´‡ì…ë‹ˆë‹¤.

íŠ¹ì • ë“±ì‚°ë¡œì— ëŒ€í•´ ìì„¸íˆ ì„¤ëª…í•  ë•Œ:
1. ìœ„ì¹˜ì™€ ê¸°ë³¸ ì •ë³´ë¥¼ ë¨¼ì € ì†Œê°œ
2. ë‚œì´ë„, ê±°ë¦¬, ì‹œê°„ ë“± ì‹¤ìš© ì •ë³´ ì„¤ëª…
3. êµí†µ/ì ‘ê·¼ì„± ì •ë³´ (ì£¼ì°¨ì¥, ëŒ€ì¤‘êµí†µ)
4. ë§¤ë ¥ í¬ì¸íŠ¸ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…
5. ì–´ë–¤ ì‚¬ëŒì—ê²Œ ì¶”ì²œí•˜ëŠ”ì§€ ë§ˆë¬´ë¦¬

ìì—°ìŠ¤ëŸ½ê³  ì¹œê·¼í•œ ë§íˆ¬ë¡œ ì‘ì„±í•˜ë˜, ëª¨ë“  ì •ë³´ëŠ” ì œê³µëœ ë°ì´í„°ì— ê¸°ë°˜í•´ì•¼ í•©ë‹ˆë‹¤."""

    user_prompt = f"""ë‹¤ìŒ ë“±ì‚°ë¡œì— ëŒ€í•´ ìì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”:

{trail_info}

ì‚¬ìš©ìê°€ ì´ ì½”ìŠ¤ë¥¼ ì„ íƒí•˜ëŠ” ë° ë„ì›€ì´ ë˜ë„ë¡ ìƒì„¸í•˜ê²Œ ì•ˆë‚´í•´ì£¼ì„¸ìš”."""

    try:
        response = client.complete_text(system_prompt, user_prompt)
        return response
    except Exception as e:
        # Fallback
        return f"""{trail_data['ìœ„ì¹˜']}ì— ìœ„ì¹˜í•œ **{trail_data['ì‚°ì´ë¦„']} {trail_data['ì½”ìŠ¤ëª…']}**ì— ëŒ€í•´ ì„¤ëª…í•´ë“œë¦´ê²Œìš”.

**ê¸°ë³¸ ì •ë³´**
- ë‚œì´ë„: {trail_data['ì„¸ë¶€ë‚œì´ë„']}
- ì´ ê±°ë¦¬: {trail_data['ì´ê±°ë¦¬_km']:.1f}km
- ìµœê³  ê³ ë„: {trail_data['ìµœê³ ê³ ë„_m']:.0f}m
- ì˜ˆìƒ ì‹œê°„: {trail_data['ì˜ˆìƒì‹œê°„']}

**ì ‘ê·¼ì„±**
- ì£¼ì°¨ì¥: {trail_data['ì£¼ì°¨ì¥ëª…']} (ì…êµ¬ì—ì„œ {trail_data['ì£¼ì°¨ì¥ê±°ë¦¬_m']:.0f}m)
- ëŒ€ì¤‘êµí†µ: {trail_data['ì •ë¥˜ì¥ëª…']} (ì…êµ¬ì—ì„œ {trail_data['ì •ë¥˜ì¥ê±°ë¦¬_m']:.0f}m)

**ë§¤ë ¥ í¬ì¸íŠ¸**
ì´ ì½”ìŠ¤ì˜ ê°€ì¥ í° ë§¤ë ¥ì€ **{trail_data['íŠ¹ì¶œë§¤ë ¥']}**ì…ë‹ˆë‹¤ ({trail_data['íŠ¹ì¶œì ìˆ˜']:.1f}ì ).
ì£¼ë³€ ê´€ê´‘ ì¸í”„ë¼ë„ {trail_data['ê´€ê´‘ì¸í”„ë¼ì ìˆ˜']:.1f}ì ìœ¼ë¡œ {'ì¢‹ì€' if trail_data['ê´€ê´‘ì¸í”„ë¼ì ìˆ˜'] >= 5 else 'ì ë‹¹í•œ'} í¸ì…ë‹ˆë‹¤.

ë” ê¶ê¸ˆí•˜ì‹  ì ì´ ìˆìœ¼ì‹œë©´ ë§ì”€í•´ì£¼ì„¸ìš”! ğŸ˜Š"""


# -----------------------------------------------------------------------------
# ë©”ì¸ ì•±
# -----------------------------------------------------------------------------
def main():
    st.set_page_config(
        page_title="ë“±ì‚°ë¡œ ì¶”ì²œ ì±—ë´‡",
        page_icon="ğŸ”ï¸",
        layout="wide"
    )
    
    st.title("ğŸ”ï¸ ë“±ì‚°ë¡œ ì¶”ì²œ ì±—ë´‡")
    st.caption("ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ë¡œ ë‚˜ì—ê²Œ ë§ëŠ” ë“±ì‚°ë¡œë¥¼ ì°¾ì•„ë³´ì„¸ìš”!")
    
    # ë°ì´í„° ë¡œë“œ
    trails_df = load_trails()
    
    if trails_df.empty:
        st.error("ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()
    
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if "messages" not in st.session_state:
        st.session_state.messages = []
        # ì´ˆê¸° ì¸ì‚¬ ë©”ì‹œì§€
        st.session_state.messages.append({
            "role": "assistant",
            "content": """ì•ˆë…•í•˜ì„¸ìš”! ë“±ì‚°ë¡œ ì¶”ì²œ ì±—ë´‡ ë“±ì‚¬ë‹ˆì…ë‹ˆë‹¤. â›°ï¸

ì‚¬ìš©ìë‹˜ê»˜ ë”± ë§ëŠ” ë“±ì‚°ë¡œë¥¼ ì¶”ì²œí•´ë“œë¦¬ê¸° ìœ„í•´ ëª‡ ê°€ì§€ë§Œ ì—¬ì­¤ë³¼ê²Œìš”.

ì˜¤ëŠ˜ì€ ì–´ë–¤ ë“±ì‚°ì„ í•˜ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?

ì˜ˆë¥¼ ë“¤ì–´:
â€¢ íë§ì´ í•„ìš”í•´ì„œ ì¡°ìš©í•˜ê³  ê²½ì¹˜ ì¢‹ì€ ê³³
â€¢ ì²´ë ¥ ë‹¨ë ¨ ëª©ì ìœ¼ë¡œ ì¢€ í˜ë“  ì½”ìŠ¤
â€¢ SNS ì¸ì¦ìƒ· ì°ê¸° ì¢‹ì€ ëª…ì†Œ
â€¢ ê³„ì ˆ í’ê²½(ë‹¨í’, ì„¤ê²½ ë“±)ì„ ì¦ê¸°ê³  ì‹¶ì€ ê³³

ì–´ë–¤ ìŠ¤íƒ€ì¼ì˜ ë“±ì‚°ë¡œë¥¼ ì›í•˜ì‹œëŠ”ì§€, ê·¸ë¦¬ê³  í¬ë§ ë‚œì´ë„ê°€ ìˆë‹¤ë©´ ë§ì”€í•´ì£¼ì„¸ìš”!"""
        })
    
    if "last_plan" not in st.session_state:
        st.session_state.last_plan = None
    if "last_results" not in st.session_state:
        st.session_state.last_results = None
    
    # Gemini í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    try:
        if "gemini" in st.secrets:
            api_key = st.secrets["gemini"]["GEMINI_API_KEY"]
            model = st.secrets["gemini"].get("GEMINI_MODEL", "gemini-2.0-flash-exp")
        elif "GEMINI_API_KEY" in st.secrets:
            api_key = st.secrets["GEMINI_API_KEY"]
            model = st.secrets.get("GEMINI_MODEL", "gemini-2.0-flash-exp")
        else:
            st.error("âš ï¸ Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            st.stop()
        
        client = GeminiClient(api_key=api_key, model=model)
        
    except Exception as e:
        st.error(f"Gemini API ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        st.stop()
    
    # ì±„íŒ… íˆìŠ¤í† ë¦¬ í‘œì‹œ
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    
    # ì‚¬ìš©ì ì…ë ¥
    user_input = st.chat_input("ì›í•˜ì‹œëŠ” ë“±ì‚° ìŠ¤íƒ€ì¼ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”...")
    
    if user_input:
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€ ë° í‘œì‹œ
        st.session_state.messages.append({"role": "user", "content": user_input})
        
        with st.chat_message("user"):
            st.markdown(user_input)
        
        # ì˜ë„ ë¶„ë¥˜
        intent = route_intent(user_input)
        
        # Assistant ì‘ë‹µ ìƒì„±
        with st.chat_message("assistant"):
            with st.spinner("ìƒê° ì¤‘..."):
                
                if intent in ("recommend", "refine"):
                    # LLM translation ìˆ˜í–‰
                    plan = translate_plan(
                        client, 
                        user_input, 
                        intent=intent,
                        last_plan=st.session_state.last_plan if intent == "refine" else None
                    )
                    
                    # ì¶”ì²œ ì—”ì§„ ì‹¤í–‰
                    results = run_recommender(trails_df, plan, top_k=5)
                    
                    # LLM ê¸°ë°˜ ìì—°ìŠ¤ëŸ¬ìš´ ì‘ë‹µ ìƒì„±
                    response = generate_conversational_recommendation(
                        client, user_input, plan, results
                    )
                    
                    # ì‘ë‹µ í‘œì‹œ
                    st.markdown(response)
                    
                    # ë©”ì‹œì§€ ì €ì¥
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": response
                    })
                    
                    # ìƒíƒœ ì—…ë°ì´íŠ¸
                    st.session_state.last_plan = plan
                    st.session_state.last_results = results
                
                elif intent == "explain":
                    # íŠ¹ì • ë“±ì‚°ë¡œì— ëŒ€í•œ ì„¤ëª… ìš”ì²­
                    if st.session_state.last_results is None or st.session_state.last_results.empty:
                        response = "ì•„ì§ ì¶”ì²œ ê²°ê³¼ê°€ ì—†ì–´ìš”. ë¨¼ì € ë“±ì‚°ë¡œë¥¼ ì¶”ì²œë°›ì•„ë³´ì„¸ìš”! ğŸ˜Š"
                        st.markdown(response)
                    else:
                        # ì‚¬ìš©ìê°€ ì–¸ê¸‰í•œ ì‚° ì´ë¦„ ì°¾ê¸°
                        mentioned_trail = None
                        for idx, row in st.session_state.last_results.iterrows():
                            if row['ì‚°ì´ë¦„'] in user_input or row['ì½”ìŠ¤ëª…'] in user_input:
                                mentioned_trail = row
                                break
                        
                        if mentioned_trail is not None:
                            # íŠ¹ì • ë“±ì‚°ë¡œ ìƒì„¸ ì„¤ëª…
                            response = generate_trail_detail_explanation(
                                client,
                                user_input,
                                mentioned_trail
                            )
                        else:
                            # ì¼ë°˜ì ì¸ ì¶”ì²œ ì´ìœ  ì„¤ëª…
                            try:
                                top_items = []
                                for idx, row in st.session_state.last_results.head(3).iterrows():
                                    top_items.append({
                                        'ì‚°ì´ë¦„': row['ì‚°ì´ë¦„'],
                                        'ì½”ìŠ¤ëª…': row['ì½”ìŠ¤ëª…'],
                                        'ì„¸ë¶€ë‚œì´ë„': row['ì„¸ë¶€ë‚œì´ë„'],
                                        'ê´€ê´‘ì¸í”„ë¼ì ìˆ˜': row['ê´€ê´‘ì¸í”„ë¼ì ìˆ˜'],
                                        'ë§¤ë ¥ì¢…í•©ì ìˆ˜': row['ë§¤ë ¥ì¢…í•©ì ìˆ˜']
                                    })
                                
                                response = client.complete_text(
                                    system_prompt=EXPLAIN_SYSTEM_PROMPT,
                                    user_prompt=make_explain_user_prompt(
                                        user_input, 
                                        st.session_state.last_plan, 
                                        top_items
                                    )
                                )
                            except Exception:
                                response = "ì´ì „ì— ì¶”ì²œí•´ë“œë¦° ë“±ì‚°ë¡œë“¤ì€ ì‚¬ìš©ìë‹˜ì˜ ì¡°ê±´ì— ê°€ì¥ ì˜ ë§ëŠ” ê³³ë“¤ì´ì—ìš”! ğŸ˜Š"
                        
                        st.markdown(response)
                    
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": response
                    })
                
                elif intent == "question":
                    # ë°ì´í„° ê¸°ë°˜ QA
                    data_summary = f"""ì „ì²´ ë“±ì‚°ë¡œ ìˆ˜: {len(trails_df)}ê°œ
í‰ê·  ë§¤ë ¥ë„: {trails_df['ë§¤ë ¥ì¢…í•©ì ìˆ˜'].mean():.1f}ì 
í‰ê·  ì¸í”„ë¼ ì ìˆ˜: {trails_df['ê´€ê´‘ì¸í”„ë¼ì ìˆ˜'].mean():.1f}ì """
                    
                    try:
                        response = client.complete_text(
                            system_prompt=QA_SYSTEM_PROMPT,
                            user_prompt=make_qa_user_prompt(user_input, data_summary)
                        )
                        st.markdown(response)
                    except Exception:
                        response = "ì£„ì†¡í•´ìš”, ê·¸ ì§ˆë¬¸ì— ëŒ€í•œ ì •í™•í•œ ë‹µë³€ì´ ì–´ë µë„¤ìš”. ğŸ˜…\n\nì›í•˜ì‹œëŠ” ë“±ì‚° ìŠ¤íƒ€ì¼ì„ ë§ì”€í•´ì£¼ì‹œë©´ ë§ì¶¤ ì¶”ì²œì„ ë„ì™€ë“œë¦´ê²Œìš”!"
                        st.markdown(response)
                    
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": response
                    })
                
                else:  # other
                    response = """ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”? ğŸ˜Š

ë‹¤ìŒê³¼ ê°™ì´ ë§ì”€í•´ì£¼ì‹œë©´ ì¢‹ì•„ìš”:
â€¢ "íë§ë˜ëŠ” ì¡°ìš©í•œ ê³³ ì¶”ì²œí•´ì¤˜"
â€¢ "ê°€ì¡±ê³¼ ê°€ê¸° ì¢‹ì€ ì‰¬ìš´ ì½”ìŠ¤"
â€¢ "ì „ë§ ì¢‹ì€ ê³³"
â€¢ "ì¢€ ë” ì‰¬ìš´ ê³³ìœ¼ë¡œ" (ì´ì „ ì¶”ì²œ ìˆ˜ì •)
â€¢ "ê°€ë¦¬ì‚° 01 ì½”ìŠ¤ì— ëŒ€í•´ ë” ì„¤ëª…í•´ì¤˜" (ìƒì„¸ ì„¤ëª…)"""
                    
                    st.markdown(response)
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": response
                    })


if __name__ == "__main__":
    main()