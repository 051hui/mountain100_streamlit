# pages/ì±—ë´‡ì¶”ì²œ.py
import pandas as pd
import streamlit as st
import os
import sys

# ìƒìœ„ ë””ë ‰í† ë¦¬ì˜ utilsë¥¼ importí•˜ê¸° ìœ„í•´
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from utils.intent_classifier import classify_intent_with_llm, extract_mountain_name
from utils.llm_client import GeminiClient
from utils.translator import translate_plan
from utils.recommender import run_recommender
from utils.llm_prompts import (
    EXPLAIN_SYSTEM_PROMPT, 
    make_explain_user_prompt,
    QA_SYSTEM_PROMPT,
    make_qa_user_prompt
)


# -----------------------------------------------------------------------------
# ë°ì´í„° ë¡œë“œ
# -----------------------------------------------------------------------------
@st.cache_data
def load_trails() -> pd.DataFrame:
    """ë“±ì‚°ë¡œ ë°ì´í„° ë¡œë“œ"""
    try:
        current_dir = os.path.dirname(os.path.abspath(__file__))
        root_dir = os.path.dirname(current_dir)
        file_path = os.path.join(root_dir, 'data', '100mountains_dashboard.csv')
        
        df = pd.read_csv(file_path)
        
        full_columns = [
            'ì½”ìŠ¤ëª…', 'ì‚°ì´ë¦„', 'ìœ í˜•ì„¤ëª…', 'ìµœê³ ê³ ë„_m', 'ëˆ„ì ìƒìŠ¹_m', 'í¸ë„ê±°ë¦¬_km', 'ì´ê±°ë¦¬_km', 
            'ì˜ˆìƒì‹œê°„_ë¶„', 'ì˜ˆìƒì‹œê°„', 'ì¶œë°œ_lat', 'ì¶œë°œ_lon', 'ë„ì°©_lat', 'ë„ì°©_lon', 
            'ë‚œì´ë„', 'ì„¸ë¶€ë‚œì´ë„', 'ë‚œì´ë„ì ìˆ˜', 'ê´€ê´‘ì¸í”„ë¼ì ìˆ˜', 'ì£¼ì°¨ì¥_ì ‘ê·¼ì„±ì ìˆ˜', 
            'ì •ë¥˜ì¥_ì ‘ê·¼ì„±ì ìˆ˜', 'ì½”ìŠ¤ìˆ˜', 'ê°€ì¤‘ì¹˜', 'ë§¤ë ¥ì¢…í•©ì ìˆ˜',
            'ì „ë§', 'íë§', 'ì‚¬ì§„', 'ë“±ì‚°ë¡œ', 'ì„±ì·¨ê°', 'ê³„ì ˆë§¤ë ¥', 'íŠ¹ì¶œë§¤ë ¥', 'íŠ¹ì¶œì ìˆ˜',
            'ì£¼ì°¨ì¥ê±°ë¦¬_m', 'ì •ë¥˜ì¥ê±°ë¦¬_m', 'ìœ„ì¹˜', 'ì£¼ì°¨ì¥ëª…', 'ì •ë¥˜ì¥ëª…', 'Cluster'
        ]
        
        if len(df.columns) == len(full_columns):
            df.columns = full_columns
        
        numeric_cols = [
            'ë‚œì´ë„ì ìˆ˜', 'ê´€ê´‘ì¸í”„ë¼ì ìˆ˜', 'ë§¤ë ¥ì¢…í•©ì ìˆ˜', 
            'ì£¼ì°¨ì¥ê±°ë¦¬_m', 'ì •ë¥˜ì¥ê±°ë¦¬_m', 'ì´ê±°ë¦¬_km', 'ìµœê³ ê³ ë„_m', 'Cluster'
        ]
        
        for col in numeric_cols:
            if col in df.columns:
                if col == 'ì£¼ì°¨ì¥ê±°ë¦¬_m':
                    df[col] = pd.to_numeric(df[col], errors='coerce').fillna(-1)
                else:
                    df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
        
        str_cols = ['ì£¼ì°¨ì¥ëª…', 'ì •ë¥˜ì¥ëª…', 'ìœ„ì¹˜']
        for col in str_cols:
            if col in df.columns:
                df[col] = df[col].fillna("-")
        
        return df
        
    except FileNotFoundError:
        st.error(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        return pd.DataFrame()


# -----------------------------------------------------------------------------
# LLM ê¸°ë°˜ ìì—°ìŠ¤ëŸ¬ìš´ ì‘ë‹µ ìƒì„±
# -----------------------------------------------------------------------------
def generate_conversational_recommendation(client: GeminiClient, user_input: str, plan: dict, results: pd.DataFrame) -> str:
    """LLMì„ ì‚¬ìš©í•˜ì—¬ ìì—°ìŠ¤ëŸ¬ìš´ ì¶”ì²œ ì‘ë‹µ ìƒì„±"""
    
    if results.empty:
        return "ì£„ì†¡í•´ìš”, ë§ì”€í•˜ì‹  ì¡°ê±´ì— ë§ëŠ” ë“±ì‚°ë¡œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ğŸ˜…\n\nì¡°ê±´ì„ ì¡°ê¸ˆ ì™„í™”í•´ì„œ ë‹¤ì‹œ ë§ì”€í•´ì£¼ì‹œê² ì–´ìš”?"
    
    # ì¶”ì²œ ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ë¡œ ì •ë¦¬
    trails_info = []
    for idx, row in results.head(3).iterrows():
        trail_text = f"""
{row['ì‚°ì´ë¦„']} {row['ì½”ìŠ¤ëª…']} ({row['ìœ„ì¹˜']})
- ë‚œì´ë„: {row['ì„¸ë¶€ë‚œì´ë„']}
- ì´ ê±°ë¦¬: {row['ì´ê±°ë¦¬_km']:.1f}km
- ê³ ë„: {row['ìµœê³ ê³ ë„_m']:.0f}m
- ì˜ˆìƒ ì‹œê°„: {row['ì˜ˆìƒì‹œê°„']}
- ì¸í”„ë¼ ì ìˆ˜: {row['ê´€ê´‘ì¸í”„ë¼ì ìˆ˜']:.1f}/10
- ë§¤ë ¥ë„: {row['ë§¤ë ¥ì¢…í•©ì ìˆ˜']:.1f}ì 
- íŠ¹ì¶œ ë§¤ë ¥: {row['íŠ¹ì¶œë§¤ë ¥']} ({row['íŠ¹ì¶œì ìˆ˜']:.1f}ì )
"""
        trails_info.append(trail_text.strip())
    
    trails_text = "\n\n".join(trails_info)
    
    system_prompt = """ë‹¹ì‹ ì€ ì¹œê·¼í•œ ë“±ì‚°ë¡œ ì¶”ì²œ ì±—ë´‡ 'ë“±ì‚¬ë‹ˆ'ì…ë‹ˆë‹¤.

ì¤‘ìš” ê·œì¹™:
- ì œê³µëœ ë“±ì‚°ë¡œ ë°ì´í„°ë§Œ ì‚¬ìš©í•˜ì„¸ìš”
- ë°ì´í„°ì— ì—†ëŠ” ì‚°ì´ë‚˜ ì½”ìŠ¤ë¥¼ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”
- ì œê³µëœ ì •ë³´ ì™¸ì—ëŠ” ì ˆëŒ€ ë§Œë“¤ì–´ë‚´ì§€ ë§ˆì„¸ìš”

ì—­í• :
- ì‚¬ìš©ìì˜ ìš”ì²­ì„ ë¶„ì„í•œ ê²°ê³¼ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì„¤ëª…í•©ë‹ˆë‹¤
- ì¶”ì²œ ë“±ì‚°ë¡œë¥¼ ëŒ€í™”í•˜ë“¯ì´ ì†Œê°œí•©ë‹ˆë‹¤
- ê° ë“±ì‚°ë¡œì˜ íŠ¹ì§•ì„ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•©ë‹ˆë‹¤
- ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•˜ì—¬ ì¹œê·¼ê°ì„ ì¤ë‹ˆë‹¤

ë‹¤ì–‘í•œ í‘œí˜„:
- ë§¤ë²ˆ ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ì‹œì‘ (ì¡°ê±´ ì •ë¦¬/ë°”ë¡œ ì¶”ì²œ/ê³µê°/ì§ˆë¬¸ ë“±)
- ë¬¸ì¥ ê¸¸ì´ì™€ ì´ëª¨ì§€ ì‚¬ìš©ëŸ‰ ë³€í™”
- ì„¤ëª… ìˆœì„œ ë³€ê²½
- ì¶”ì²œ ì´ìœ  í‘œí˜„ ë‹¤ì–‘í™”

ì£¼ì˜ì‚¬í•­:
- ë°ì´í„°ì— ì—†ëŠ” ì •ë³´ëŠ” ì ˆëŒ€ ë§Œë“¤ì§€ ë§ˆì„¸ìš”
- ì œê³µëœ ë“±ì‚°ë¡œë§Œ ì–¸ê¸‰í•˜ì„¸ìš”
- ìì—°ìŠ¤ëŸ½ê³  ì¹œê·¼í•œ ë§íˆ¬ ì‚¬ìš©
- ë§¤ë²ˆ ê°™ì€ íŒ¨í„´ìœ¼ë¡œ ë‹µí•˜ì§€ ë§ˆì„¸ìš”"""

    user_prompt = f"""ì‚¬ìš©ì ìš”ì²­: "{user_input}"

ì¶”ì²œëœ ë“±ì‚°ë¡œ ì •ë³´:
{trails_text}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì¶”ì²œí•´ì£¼ì„¸ìš”.
ì œê³µëœ ë“±ì‚°ë¡œë§Œ ì–¸ê¸‰í•˜ê³ , ë§¤ë²ˆ ë‹¤ë¥¸ ìŠ¤íƒ€ì¼ë¡œ ë‹µë³€í•˜ì„¸ìš”."""

    try:
        response = client.complete_text(system_prompt, user_prompt, temperature=1.0)
        return response
    except Exception as e:
        fallback = f"""ì¢‹ìŠµë‹ˆë‹¤! ì‚¬ìš©ìë‹˜ì˜ ì¡°ê±´ì— ë§ëŠ” ë“±ì‚°ë¡œë¥¼ ì°¾ì•˜ì–´ìš”.

ğŸ”ï¸ ì¶”ì²œ ë“±ì‚°ë¡œ

"""
        for idx, row in results.head(3).iterrows():
            fallback += f"""**{row['ì‚°ì´ë¦„']} {row['ì½”ìŠ¤ëª…']}** ({row['ìœ„ì¹˜']})
ì¶”ì²œ ì´ìœ : ë‚œì´ë„ {row['ì„¸ë¶€ë‚œì´ë„']}, {row['íŠ¹ì¶œë§¤ë ¥']} ì ìˆ˜ê°€ ë†’ìŠµë‹ˆë‹¤.
íŠ¹ì§•: ì´ {row['ì´ê±°ë¦¬_km']:.1f}km, ì˜ˆìƒ ì‹œê°„ {row['ì˜ˆìƒì‹œê°„']}

"""
        fallback += "\nì–´ë– ì„¸ìš”? ë” ê¶ê¸ˆí•œ ì ì´ë‚˜ ë‹¤ë¥¸ ì˜µì…˜ì´ í•„ìš”í•˜ì‹œë©´ ë§ì”€í•´ì£¼ì„¸ìš”! ğŸŒ²"
        return fallback


def generate_trail_detail_explanation(client: GeminiClient, trail_name: str, trail_data: pd.Series) -> str:
    """íŠ¹ì • ë“±ì‚°ë¡œì— ëŒ€í•œ ìƒì„¸ ì„¤ëª… ìƒì„±"""
    
    trail_info = f"""
ë“±ì‚°ë¡œ: {trail_data['ì‚°ì´ë¦„']} {trail_data['ì½”ìŠ¤ëª…']}
ìœ„ì¹˜: {trail_data['ìœ„ì¹˜']}
ë‚œì´ë„: {trail_data['ì„¸ë¶€ë‚œì´ë„']}
ì´ ê±°ë¦¬: {trail_data['ì´ê±°ë¦¬_km']:.1f}km
ìµœê³  ê³ ë„: {trail_data['ìµœê³ ê³ ë„_m']:.0f}m
ì˜ˆìƒ ì‹œê°„: {trail_data['ì˜ˆìƒì‹œê°„']}
ì£¼ì°¨ì¥: {trail_data['ì£¼ì°¨ì¥ëª…']} (ê±°ë¦¬: {trail_data['ì£¼ì°¨ì¥ê±°ë¦¬_m']:.0f}m)
ì •ë¥˜ì¥: {trail_data['ì •ë¥˜ì¥ëª…']} (ê±°ë¦¬: {trail_data['ì •ë¥˜ì¥ê±°ë¦¬_m']:.0f}m)
ê´€ê´‘ ì¸í”„ë¼ ì ìˆ˜: {trail_data['ê´€ê´‘ì¸í”„ë¼ì ìˆ˜']:.1f}/10
ë§¤ë ¥ ì¢…í•© ì ìˆ˜: {trail_data['ë§¤ë ¥ì¢…í•©ì ìˆ˜']:.1f}ì 
ë§¤ë ¥ ìš”ì†Œ: ì „ë§ {trail_data['ì „ë§']:.1f}, íë§ {trail_data['íë§']:.1f}, ì‚¬ì§„ {trail_data['ì‚¬ì§„']:.1f}, ì„±ì·¨ê° {trail_data['ì„±ì·¨ê°']:.1f}, ê³„ì ˆë§¤ë ¥ {trail_data['ê³„ì ˆë§¤ë ¥']:.1f}
íŠ¹ì¶œ ë§¤ë ¥: {trail_data['íŠ¹ì¶œë§¤ë ¥']} ({trail_data['íŠ¹ì¶œì ìˆ˜']:.1f}ì )
"""
    
    system_prompt = """ì¹œê·¼í•œ ë“±ì‚°ë¡œ ì•ˆë‚´ ì±—ë´‡ì…ë‹ˆë‹¤.

íŠ¹ì • ë“±ì‚°ë¡œ ìƒì„¸ ì„¤ëª… ì‹œ:
1. ìœ„ì¹˜ì™€ ê¸°ë³¸ ì •ë³´ ì†Œê°œ
2. ë‚œì´ë„, ê±°ë¦¬, ì‹œê°„ ë“± ì‹¤ìš© ì •ë³´
3. êµí†µ/ì ‘ê·¼ì„± ì •ë³´
4. ë§¤ë ¥ í¬ì¸íŠ¸ êµ¬ì²´ì  ì„¤ëª…
5. ì–´ë–¤ ì‚¬ëŒì—ê²Œ ì¶”ì²œí•˜ëŠ”ì§€

ìì—°ìŠ¤ëŸ½ê³  ì¹œê·¼í•œ ë§íˆ¬ë¡œ, ëª¨ë“  ì •ë³´ëŠ” ì œê³µëœ ë°ì´í„°ì— ê¸°ë°˜í•˜ì„¸ìš”."""

    user_prompt = f"""ë‹¤ìŒ ë“±ì‚°ë¡œì— ëŒ€í•´ ìì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”:

{trail_info}

ì‚¬ìš©ìê°€ ì´ ì½”ìŠ¤ë¥¼ ì„ íƒí•˜ëŠ” ë° ë„ì›€ì´ ë˜ë„ë¡ ìƒì„¸í•˜ê²Œ ì•ˆë‚´í•´ì£¼ì„¸ìš”."""

    try:
        response = client.complete_text(system_prompt, user_prompt, temperature=0.7)
        return response
    except Exception as e:
        return f"""{trail_data['ìœ„ì¹˜']}ì— ìœ„ì¹˜í•œ **{trail_data['ì‚°ì´ë¦„']} {trail_data['ì½”ìŠ¤ëª…']}**ì— ëŒ€í•´ ì„¤ëª…í•´ë“œë¦´ê²Œìš”.

**ê¸°ë³¸ ì •ë³´**
- ë‚œì´ë„: {trail_data['ì„¸ë¶€ë‚œì´ë„']}
- ì´ ê±°ë¦¬: {trail_data['ì´ê±°ë¦¬_km']:.1f}km
- ìµœê³  ê³ ë„: {trail_data['ìµœê³ ê³ ë„_m']:.0f}m
- ì˜ˆìƒ ì‹œê°„: {trail_data['ì˜ˆìƒì‹œê°„']}

**ì ‘ê·¼ì„±**
- ì£¼ì°¨ì¥: {trail_data['ì£¼ì°¨ì¥ëª…']} (ì…êµ¬ì—ì„œ {trail_data['ì£¼ì°¨ì¥ê±°ë¦¬_m']:.0f}m)
- ëŒ€ì¤‘êµí†µ: {trail_data['ì •ë¥˜ì¥ëª…']} (ì…êµ¬ì—ì„œ {trail_data['ì •ë¥˜ì¥ê±°ë¦¬_m']:.0f}m)

**ë§¤ë ¥ í¬ì¸íŠ¸**
ì´ ì½”ìŠ¤ì˜ ê°€ì¥ í° ë§¤ë ¥ì€ **{trail_data['íŠ¹ì¶œë§¤ë ¥']}**ì…ë‹ˆë‹¤.

ë” ê¶ê¸ˆí•˜ì‹  ì ì´ ìˆìœ¼ì‹œë©´ ë§ì”€í•´ì£¼ì„¸ìš”! ğŸ˜Š"""


# -----------------------------------------------------------------------------
# ë©”ì¸ ì•±
# -----------------------------------------------------------------------------
def main():
    st.set_page_config(
        page_title="ë“±ì‚°ë¡œ ì¶”ì²œ ì±—ë´‡",
        page_icon="ğŸ”ï¸",
        layout="wide"
    )
    
    st.title("ğŸ”ï¸ ë“±ì‚°ë¡œ ì¶”ì²œ ì±—ë´‡")
    st.caption("ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ë¡œ ë‚˜ì—ê²Œ ë§ëŠ” ë“±ì‚°ë¡œë¥¼ ì°¾ì•„ë³´ì„¸ìš”!")
    
    # ë°ì´í„° ë¡œë“œ
    trails_df = load_trails()
    
    if trails_df.empty:
        st.error("ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()
    
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if "messages" not in st.session_state:
        st.session_state.messages = []
        st.session_state.messages.append({
            "role": "assistant",
            "content": """ì•ˆë…•í•˜ì„¸ìš”! ë“±ì‚°ë¡œ ì¶”ì²œ ì±—ë´‡ ë“±ì‚¬ë‹ˆì…ë‹ˆë‹¤. â›°ï¸

ì‚¬ìš©ìë‹˜ê»˜ ë”± ë§ëŠ” ë“±ì‚°ë¡œë¥¼ ì¶”ì²œí•´ë“œë¦¬ê¸° ìœ„í•´ ëª‡ ê°€ì§€ë§Œ ì—¬ì­¤ë³¼ê²Œìš”.

ì˜¤ëŠ˜ì€ ì–´ë–¤ ë“±ì‚°ì„ í•˜ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?

ì˜ˆë¥¼ ë“¤ì–´:
â€¢ íë§ì´ í•„ìš”í•´ì„œ ì¡°ìš©í•˜ê³  ê²½ì¹˜ ì¢‹ì€ ê³³
â€¢ ì²´ë ¥ ë‹¨ë ¨ ëª©ì ìœ¼ë¡œ ì¢€ í˜ë“  ì½”ìŠ¤
â€¢ SNS ì¸ì¦ìƒ· ì°ê¸° ì¢‹ì€ ëª…ì†Œ
â€¢ ê³„ì ˆ í’ê²½(ë‹¨í’, ì„¤ê²½ ë“±)ì„ ì¦ê¸°ê³  ì‹¶ì€ ê³³

ì–´ë–¤ ìŠ¤íƒ€ì¼ì˜ ë“±ì‚°ë¡œë¥¼ ì›í•˜ì‹œëŠ”ì§€, ê·¸ë¦¬ê³  í¬ë§ ë‚œì´ë„ê°€ ìˆë‹¤ë©´ ë§ì”€í•´ì£¼ì„¸ìš”!"""
        })
    
    if "last_plan" not in st.session_state:
        st.session_state.last_plan = None
    if "last_results" not in st.session_state:
        st.session_state.last_results = None
    
    # Gemini í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    try:
        if "gemini" in st.secrets:
            api_key = st.secrets["gemini"]["GEMINI_API_KEY"]
            model = st.secrets["gemini"].get("GEMINI_MODEL", "gemini-2.0-flash-exp")
        elif "GEMINI_API_KEY" in st.secrets:
            api_key = st.secrets["GEMINI_API_KEY"]
            model = st.secrets.get("GEMINI_MODEL", "gemini-2.0-flash-exp")
        else:
            st.error("âš ï¸ Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            st.stop()
        
        client = GeminiClient(api_key=api_key, model=model)
        
    except Exception as e:
        st.error(f"Gemini API ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        st.stop()
    
    # ì±„íŒ… íˆìŠ¤í† ë¦¬ í‘œì‹œ
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    
    # ì‚¬ìš©ì ì…ë ¥
    user_input = st.chat_input("ì›í•˜ì‹œëŠ” ë“±ì‚° ìŠ¤íƒ€ì¼ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”...")
    
    if user_input:
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€ ë° í‘œì‹œ
        st.session_state.messages.append({"role": "user", "content": user_input})
        
        with st.chat_message("user"):
            st.markdown(user_input)
        
        # ì˜ë„ ë¶„ë¥˜ (LLM ê¸°ë°˜)
        has_previous = st.session_state.last_results is not None and not st.session_state.last_results.empty
        intent = classify_intent_with_llm(client, user_input, has_previous_results=has_previous)
        
        # Assistant ì‘ë‹µ ìƒì„±
        with st.chat_message("assistant"):
            with st.spinner("ìƒê° ì¤‘..."):
                
                if intent in ("recommend", "refine"):
                    # íŠ¹ì • ì‚°ì´ ì–¸ê¸‰ë˜ì—ˆëŠ”ì§€ í™•ì¸
                    all_mountains = trails_df['ì‚°ì´ë¦„'].unique().tolist()
                    mentioned_mountain = extract_mountain_name(user_input, all_mountains)
                    
                    # LLM translation ìˆ˜í–‰
                    plan = translate_plan(
                        client, 
                        user_input, 
                        intent=intent,
                        last_plan=st.session_state.last_plan if intent == "refine" else None
                    )
                    
                    # íŠ¹ì • ì‚°ì´ ì–¸ê¸‰ë˜ì—ˆìœ¼ë©´ í•„í„°ë§ ì¶”ê°€
                    if mentioned_mountain:
                        if "exclude" not in plan:
                            plan["exclude"] = {"mountains": [], "trails": []}
                        all_mountains_set = set(trails_df['ì‚°ì´ë¦„'].unique())
                        other_mountains = all_mountains_set - {mentioned_mountain}
                        plan["exclude"]["mountains"] = list(other_mountains)
                    
                    # ì¶”ì²œ ì—”ì§„ ì‹¤í–‰
                    results = run_recommender(trails_df, plan, top_k=5)
                    
                    # LLM ê¸°ë°˜ ìì—°ìŠ¤ëŸ¬ìš´ ì‘ë‹µ ìƒì„±
                    response = generate_conversational_recommendation(
                        client, user_input, plan, results
                    )
                    
                    st.markdown(response)
                    
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": response
                    })
                    
                    st.session_state.last_plan = plan
                    st.session_state.last_results = results
                
                elif intent == "explain":
                    if st.session_state.last_results is None or st.session_state.last_results.empty:
                        response = "ì•„ì§ ì¶”ì²œ ê²°ê³¼ê°€ ì—†ì–´ìš”. ë¨¼ì € ë“±ì‚°ë¡œë¥¼ ì¶”ì²œë°›ì•„ë³´ì„¸ìš”! ğŸ˜Š"
                        st.markdown(response)
                    else:
                        # ì‚¬ìš©ìê°€ ì–¸ê¸‰í•œ ì‚°/ì½”ìŠ¤ ì°¾ê¸°
                        mentioned_trail = None
                        user_clean = user_input.replace(" ", "").replace("ë²ˆ", "").replace("ì½”ìŠ¤", "")
                        
                        for idx, row in st.session_state.last_results.iterrows():
                            mountain_clean = row['ì‚°ì´ë¦„'].replace(" ", "")
                            course_clean = row['ì½”ìŠ¤ëª…'].replace(" ", "").replace("_", "")
                            
                            if (mountain_clean in user_clean or 
                                course_clean in user_clean or
                                row['ì‚°ì´ë¦„'] in user_input or 
                                row['ì½”ìŠ¤ëª…'] in user_input):
                                mentioned_trail = row
                                break
                        
                        if mentioned_trail is not None:
                            response = generate_trail_detail_explanation(
                                client, user_input, mentioned_trail
                            )
                        else:
                            try:
                                top_items = []
                                for idx, row in st.session_state.last_results.head(3).iterrows():
                                    top_items.append({
                                        'ì‚°ì´ë¦„': row['ì‚°ì´ë¦„'],
                                        'ì½”ìŠ¤ëª…': row['ì½”ìŠ¤ëª…'],
                                        'ì„¸ë¶€ë‚œì´ë„': row['ì„¸ë¶€ë‚œì´ë„'],
                                        'ê´€ê´‘ì¸í”„ë¼ì ìˆ˜': row['ê´€ê´‘ì¸í”„ë¼ì ìˆ˜'],
                                        'ë§¤ë ¥ì¢…í•©ì ìˆ˜': row['ë§¤ë ¥ì¢…í•©ì ìˆ˜']
                                    })
                                
                                response = client.complete_text(
                                    system_prompt=EXPLAIN_SYSTEM_PROMPT,
                                    user_prompt=make_explain_user_prompt(
                                        user_input, 
                                        st.session_state.last_plan, 
                                        top_items
                                    ),
                                    temperature=0.7
                                )
                            except Exception:
                                response = "ì´ì „ì— ì¶”ì²œí•´ë“œë¦° ë“±ì‚°ë¡œë“¤ì€ ì‚¬ìš©ìë‹˜ì˜ ì¡°ê±´ì— ê°€ì¥ ì˜ ë§ëŠ” ê³³ë“¤ì´ì—ìš”! ğŸ˜Š"
                        
                        st.markdown(response)
                    
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": response
                    })
                
                elif intent == "question":
                    # íŠ¹ì • ì‚°ì— ëŒ€í•œ ì§ˆë¬¸ì¸ì§€ í™•ì¸
                    all_mountains = trails_df['ì‚°ì´ë¦„'].unique().tolist()
                    mentioned_mountain = extract_mountain_name(user_input, all_mountains)
                    
                    if mentioned_mountain:
                        mountain_trails = trails_df[trails_df['ì‚°ì´ë¦„'] == mentioned_mountain]
                        
                        if not mountain_trails.empty:
                            trail_info = f"""
{mentioned_mountain}ì— ëŒ€í•œ ì •ë³´:
- ì´ {len(mountain_trails)}ê°œì˜ ì½”ìŠ¤
- í‰ê·  ë‚œì´ë„: {mountain_trails['ì„¸ë¶€ë‚œì´ë„'].mode()[0] if not mountain_trails['ì„¸ë¶€ë‚œì´ë„'].mode().empty else 'ì¤‘ê¸‰'}
- í‰ê·  ì´ ê±°ë¦¬: {mountain_trails['ì´ê±°ë¦¬_km'].mean():.1f}km
- í‰ê·  ê³ ë„: {mountain_trails['ìµœê³ ê³ ë„_m'].mean():.0f}m
- ìœ„ì¹˜: {mountain_trails.iloc[0]['ìœ„ì¹˜']}
- ì£¼ìš” ë§¤ë ¥: {mountain_trails.iloc[0]['íŠ¹ì¶œë§¤ë ¥']}

ì½”ìŠ¤ ëª©ë¡:
"""
                            for idx, row in mountain_trails.iterrows():
                                trail_info += f"- {row['ì½”ìŠ¤ëª…']}: ë‚œì´ë„ {row['ì„¸ë¶€ë‚œì´ë„']}, ê±°ë¦¬ {row['ì´ê±°ë¦¬_km']:.1f}km\n"
                            
                            system_prompt = """ì¹œê·¼í•œ ë“±ì‚°ë¡œ ì•ˆë‚´ ì±—ë´‡ì…ë‹ˆë‹¤.
íŠ¹ì • ì‚° ì§ˆë¬¸ ë‹µë³€ ì‹œ:
1. ê¸°ë³¸ ì •ë³´ ì†Œê°œ
2. ì½”ìŠ¤ë“¤ ê°„ë‹¨íˆ ì„¤ëª…
3. ì‚¬ìš©ì ì¡°ê±´(ë‚œì´ë„ ë“±) ì–¸ê¸‰ ì‹œ ë§ëŠ” ì½”ìŠ¤ ì¶”ì²œ
4. ë” ìì„¸í•œ ì¶”ì²œ ìœ ë„

ìì—°ìŠ¤ëŸ½ê³  ì¹œê·¼í•œ ë§íˆ¬ë¡œ ì‘ì„±í•˜ì„¸ìš”."""
                            
                            user_prompt = f"""ì‚¬ìš©ì ì§ˆë¬¸: "{user_input}"

{mentioned_mountain} ë°ì´í„°:
{trail_info}

ìœ„ ì •ë³´ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë‹µë³€í•˜ê³ , ì¡°ê±´ ì–¸ê¸‰ ì‹œ ë§ëŠ” ì½”ìŠ¤ ì¶”ì²œí•´ì£¼ì„¸ìš”."""
                            
                            try:
                                response = client.complete_text(system_prompt, user_prompt, temperature=0.8)
                                st.markdown(response)
                            except Exception:
                                response = f"""{mentioned_mountain}ì— ëŒ€í•´ ì•Œë ¤ë“œë¦´ê²Œìš”!

{mentioned_mountain}ëŠ” {mountain_trails.iloc[0]['ìœ„ì¹˜']}ì— ìœ„ì¹˜í•œ ì‚°ìœ¼ë¡œ, ì´ {len(mountain_trails)}ê°œì˜ ì½”ìŠ¤ê°€ ìˆì–´ìš”.

ì£¼ìš” ë§¤ë ¥ì€ **{mountain_trails.iloc[0]['íŠ¹ì¶œë§¤ë ¥']}**ì´ê³ , í‰ê· ì ìœ¼ë¡œ {mountain_trails['ì´ê±°ë¦¬_km'].mean():.1f}km ì •ë„ì…ë‹ˆë‹¤.

ì–´ë–¤ ìŠ¤íƒ€ì¼ì˜ ì½”ìŠ¤ë¥¼ ì›í•˜ì‹œëŠ”ì§€ ë§ì”€í•´ì£¼ì‹œë©´ ë” ìì„¸í•œ ì¶”ì²œì„ í•´ë“œë¦´ê²Œìš”! ğŸ˜Š"""
                                st.markdown(response)
                        else:
                            response = f"ì£„ì†¡í•´ìš”, {mentioned_mountain}ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ë„¤ìš”. ğŸ˜…"
                            st.markdown(response)
                    else:
                        data_summary = f"""ì „ì²´ ë“±ì‚°ë¡œ ìˆ˜: {len(trails_df)}ê°œ
í‰ê·  ë§¤ë ¥ë„: {trails_df['ë§¤ë ¥ì¢…í•©ì ìˆ˜'].mean():.1f}ì 
í‰ê·  ì¸í”„ë¼ ì ìˆ˜: {trails_df['ê´€ê´‘ì¸í”„ë¼ì ìˆ˜'].mean():.1f}ì 

ì‚° ëª©ë¡ (ì¼ë¶€): {', '.join([str(m).strip() for m in trails_df['ì‚°ì´ë¦„'].unique()[:10]])}..."""
                        
                        try:
                            response = client.complete_text(
                                system_prompt=QA_SYSTEM_PROMPT,
                                user_prompt=make_qa_user_prompt(user_input, data_summary),
                                temperature=0.7
                            )
                            st.markdown(response)
                        except Exception:
                            response = "ì£„ì†¡í•´ìš”, ê·¸ ì§ˆë¬¸ì— ëŒ€í•œ ì •í™•í•œ ë‹µë³€ì´ ì–´ë µë„¤ìš”. ğŸ˜…\n\nì›í•˜ì‹œëŠ” ë“±ì‚° ìŠ¤íƒ€ì¼ì„ ë§ì”€í•´ì£¼ì‹œë©´ ë§ì¶¤ ì¶”ì²œì„ ë„ì™€ë“œë¦´ê²Œìš”!"
                            st.markdown(response)
                    
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": response
                    })
                
                else:  # other
                    response = """ì£„ì†¡í•˜ì§€ë§Œ ì˜ ì´í•´í•˜ì§€ ëª»í–ˆì–´ìš”. ğŸ˜…

ì €ëŠ” ë“±ì‚°ë¡œ ì¶”ì²œ ì „ë¬¸ ì±—ë´‡ì´ì—ìš”. ë‹¤ìŒê³¼ ê°™ì´ ë§ì”€í•´ì£¼ì‹œë©´ ë„ì›€ì„ ë“œë¦´ ìˆ˜ ìˆì–´ìš”:

â€¢ "íë§ë˜ëŠ” ì¡°ìš©í•œ ê³³ ì¶”ì²œí•´ì¤˜"
â€¢ "ê°€ì¡±ê³¼ ê°€ê¸° ì¢‹ì€ ì‰¬ìš´ ì½”ìŠ¤"
â€¢ "ì „ë§ ì¢‹ì€ ê³³"
â€¢ "ì¢€ ë” ì‰¬ìš´ ê³³ìœ¼ë¡œ" (ì´ì „ ì¶”ì²œ ìˆ˜ì •)
â€¢ "ê°€ë¦¬ì‚° 01 ì½”ìŠ¤ì— ëŒ€í•´ ë” ì„¤ëª…í•´ì¤˜"

ë“±ì‚°ë¡œë‚˜ ì‚°ì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œë©´ í¸í•˜ê²Œ ë¬¼ì–´ë³´ì„¸ìš”! ğŸ˜Š"""
                    
                    st.markdown(response)
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": response
                    })


if __name__ == "__main__":
    main()